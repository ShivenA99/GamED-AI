# GamED.AI v2 Environment Configuration
# Copy this file to .env and fill in your API keys

# =============================================================================
# LLM API KEYS (at least one required)
# =============================================================================

# *** RECOMMENDED FOR TESTING: Groq (FREE!) ***
# Sign up at: https://console.groq.com
# Free tier: 14,400 requests/day, 6,000 tokens/minute
# Models: Llama 3.1 70B, Llama 3.1 8B, Mixtral 8x7B
GROQ_API_KEY=gsk_your-groq-key-here

# OpenAI API Key (for GPT-4o, GPT-4-turbo, etc.)
# Paid API - pricing at https://openai.com/pricing
OPENAI_API_KEY=sk-your-openai-key-here

# Anthropic API Key (for Claude Opus, Sonnet, Haiku)
# Paid API - pricing at https://anthropic.com/pricing
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Google API Key (for Gemini models and Imagen)
# Get your key at: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=your-google-api-key-here

# =============================================================================
# AGENT MODEL CONFIGURATION (optional)
# =============================================================================

# Choose a preset configuration for all agents:
# - groq_free: FREE! Uses Groq models (Llama 3, Mixtral) - RECOMMENDED FOR TESTING
# - cost_optimized: Uses cheapest models (~$0.01-0.02/run)
# - quality_optimized: Uses best models (~$0.20-0.50/run)
# - balanced: Good quality/cost ratio (~$0.05-0.10/run) [DEFAULT]
# - anthropic_only: Only Claude models (no OpenAI dependency)
# - openai_only: Only GPT models (no Anthropic dependency)
AGENT_CONFIG_PRESET=balanced
# For free testing, use: AGENT_CONFIG_PRESET=groq_free

# Override specific agent models (optional):
# AGENT_MODEL_BLUEPRINT_GENERATOR=gpt-4o
# AGENT_MODEL_STORY_GENERATOR=claude-opus
# AGENT_MODEL_ROUTER=claude-haiku

# Override specific agent temperatures (optional):
# AGENT_TEMPERATURE_STORY_GENERATOR=0.9
# AGENT_TEMPERATURE_BLUEPRINT_GENERATOR=0.4

# =============================================================================
# DATABASE (optional, defaults to SQLite)
# =============================================================================

# DATABASE_URL=sqlite:///./gamed_ai.db
# DATABASE_URL=postgresql://user:pass@localhost/gamed_ai

# =============================================================================
# PIPELINE PRESETS (for INTERACTIVE_DIAGRAM template)
# =============================================================================

# Pipeline preset for diagram generation:
# - default: Standard pipeline with image classification and SAM-based segmentation
# - label_diagram_hierarchical: AI-generated diagrams with Gemini zone detection
#   Requires: GOOGLE_API_KEY for Gemini, optionally OPENAI_API_KEY for DALL-E
PIPELINE_PRESET=default

# Diagram generator for hierarchical preset (when PIPELINE_PRESET=label_diagram_hierarchical):
# - gemini: Use Gemini Imagen (requires GOOGLE_API_KEY)
# - openai: Use DALL-E 3 (requires OPENAI_API_KEY)
DIAGRAM_GENERATOR=gemini

# =============================================================================
# IMAGE PIPELINE CONFIGURATION (for INTERACTIVE_DIAGRAM template)
# =============================================================================

# Enable image-based diagram generation
USE_IMAGE_DIAGRAMS=true

# Web Search API (required for image retrieval)
# Sign up at: https://serper.dev (free tier available)
SERPER_API_KEY=your-serper-api-key-here

# =============================================================================
# SAM SEGMENTATION MODELS (for semantic image segmentation)
# =============================================================================

# SAM3 (Segment Anything Model 3) - PREFERRED
# Official installation: pip install sam3
# For Apple Silicon (M1/M2/M3/M4): Use MLX version for better performance
# MLX installation: pip install git+https://github.com/mlx-community/sam3-image.git
# Model will be auto-downloaded from HuggingFace on first use
USE_SAM3_MLX=auto  # auto (detect Apple Silicon), true, or false
SAM3_MLX_MODEL=mlx-community/sam3-image  # MLX model from HuggingFace
SAM3_MODEL_PATH=/path/to/sam3_checkpoint.pth  # Optional: local SAM3 checkpoint

# SAM2 Model (fallback if SAM3 not available)
# Download from: https://github.com/facebookresearch/segment-anything-2
# Recommended: sam2_hiera_base_plus (~200MB)
SAM2_MODEL_PATH=/path/to/sam2_hiera_base_plus.pth
SAM2_MODEL_TYPE=sam2_hiera_base_plus

# SAM v1 Model (fallback if SAM3/SAM2 not available)
# Download from: https://github.com/facebookresearch/segment-anything#model-checkpoints
# Recommended: sam_vit_b.pth (~375MB) - smallest, fastest
# Alternative: sam_vit_h.pth (~2.4GB) - highest quality
SAM_MODEL_PATH=/path/to/sam_vit_b.pth

# =============================================================================
# VISION LANGUAGE MODEL (VLM) - for zone labeling
# =============================================================================

# Ollama VLM Configuration (for semantic zone labeling)
# Install Ollama: https://ollama.com
# For Apple Silicon M4 with 16GB RAM, recommended models:
# - llava:7b (smaller, faster) - RECOMMENDED for 16GB RAM
# - llava:latest (larger, better quality but needs more RAM)
# Then run: ollama pull llava:7b
USE_OLLAMA=false
OLLAMA_BASE_URL=http://localhost:11434
VLM_MODEL=llava:7b  # Use llava:7b for 16GB RAM, llava:latest for more RAM

# =============================================================================
# IMAGE CLEANING (label removal via inpainting)
# =============================================================================

# EasyOCR GPU usage (set to false if no GPU available)
EASYOCR_GPU=true

# Inpaint Anything Configuration (optional, for advanced inpainting)
# Clone from: https://github.com/geekyutao/Inpaint-Anything
INPAINT_ANYTHING_PATH=./third_party/Inpaint-Anything
SAM_CKPT=/path/to/sam_vit_h_4b8939.pth
LAMA_CKPT=/path/to/big-lama

# Alternative: IOPaint server URL (if using IOPaint for inpainting)
# IOPAINT_URL=http://localhost:7860

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# CORS origins (comma-separated list of allowed origins)
# Default: http://localhost:3000,http://127.0.0.1:3000
# For production: CORS_ORIGINS=https://yourdomain.com
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# =============================================================================
# LANGSMITH TRACING (optional, for debugging)
# =============================================================================

# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=ls_your-langsmith-key
# LANGCHAIN_PROJECT=gamed-ai-v2
